{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image Classification ê³¼ì œ\n",
    "> ì¸ê³µì§€ëŠ¥ ìŠ¤í„°ë”” ë‘ ë²ˆì§¸ ê³¼ì œì— ì˜¤ì‹  ê²ƒì„ í™˜ì˜í•©ë‹ˆë‹¤! ê°•ì˜ë¥¼ ë“¤ìœ¼ë©´ì„œ ë°°ìš´ ë‹¤ì–‘í•œ ì§€ì‹ë“¤ì„ ì‹¤ìŠµì„ í†µí•´ì„œ í™œìš©í•´ë³¼ ì‹œê°„ì„ ê°€ì§ˆ ê²ƒì…ë‹ˆë‹¤!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ğŸ™ ê°•ì˜ì—ì„œ ë°°ìš´ ì´ë¯¸ì§€ ë¶„ë¥˜(Image Classification) ì‘ì—…ì„ ì§ì ‘ ì‹¤ìŠµì„ í†µí•´ í›ˆë ¨(Train)ë¶€í„° í…ŒìŠ¤íŠ¸(Test)ê¹Œì§€ ì§„í–‰í•´ë³´ì•„ìš”. í•¨ê»˜ ì‹œì‘í•´ë´…ì‹œë‹¤! ğŸ˜Š"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ğŸ‘¨â€ğŸ’» <font color='green'><b>[ ì½”ë”© ]</b></font> ì´ë¯¸ì§€ ë¶„ë¥˜ê¸° í•™ìŠµí•˜ê¸°\n",
    "```python\n",
    "ğŸ™\n",
    "ì½”ë“œë¥¼ ì‹¤í–‰í•˜ë©´ì„œ ë¶„ë¥˜ê¸°ë¥¼ í•™ìŠµí•´ë³´ì•„ìš”\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# ë¶„ë¥˜ê¸°(Classifier) í•™ìŠµí•˜ê¸°\n",
    "\n",
    "ì§€ê¸ˆê¹Œì§€ ì–´ë–»ê²Œ ì‹ ê²½ë§ì„ ì •ì˜í•˜ê³ , ì†ì‹¤ì„ ê³„ì‚°í•˜ë©° ë˜ ê°€ì¤‘ì¹˜ë¥¼ ê°±ì‹ í•˜ëŠ”ì§€ì—\n",
    "ëŒ€í•´ì„œ ë°°ì› ìŠµë‹ˆë‹¤.\n",
    "\n",
    "ì´ì œ ì•„ë§ˆë„ ì´ëŸ° ìƒê°ì„ í•˜ê³  ê³„ì‹¤í…ë°ìš”,\n",
    "\n",
    "## ë°ì´í„°ëŠ” ì–´ë–»ê²Œ í•˜ë‚˜ìš”?\n",
    "\n",
    "ì¼ë°˜ì ìœ¼ë¡œ ì´ë¯¸ì§€ë‚˜ í…ìŠ¤íŠ¸, ì˜¤ë””ì˜¤ë‚˜ ë¹„ë””ì˜¤ ë°ì´í„°ë¥¼ ë‹¤ë£° ë•ŒëŠ” í‘œì¤€ Python íŒ¨í‚¤ì§€ë¥¼\n",
    "ì´ìš©í•˜ì—¬ NumPy ë°°ì—´ë¡œ ë¶ˆëŸ¬ì˜¤ë©´ ë©ë‹ˆë‹¤. ê·¸ í›„ ê·¸ ë°°ì—´ì„ ``torch.*Tensor`` ë¡œ ë³€í™˜í•©ë‹ˆë‹¤.\n",
    "\n",
    "-  ì´ë¯¸ì§€ëŠ” Pillowë‚˜ OpenCV ê°™ì€ íŒ¨í‚¤ì§€ê°€ ìœ ìš©í•©ë‹ˆë‹¤.\n",
    "-  ì˜¤ë””ì˜¤ë¥¼ ì²˜ë¦¬í•  ë•ŒëŠ” SciPyì™€ LibROSAê°€ ìœ ìš©í•˜ê³ ìš”.\n",
    "-  í…ìŠ¤íŠ¸ì˜ ê²½ìš°ì—ëŠ” ê·¸ëƒ¥ Pythonì´ë‚˜ Cythonì„ ì‚¬ìš©í•´ë„ ë˜ê³ , NLTKë‚˜ SpaCyë„\n",
    "   ìœ ìš©í•©ë‹ˆë‹¤.\n",
    "\n",
    "íŠ¹ë³„íˆ ì˜ìƒ ë¶„ì•¼ë¥¼ ìœ„í•œ ``torchvision`` ì´ë¼ëŠ” íŒ¨í‚¤ì§€ê°€ ë§Œë“¤ì–´ì ¸ ìˆëŠ”ë°,\n",
    "ì—¬ê¸°ì—ëŠ” ImageNetì´ë‚˜ CIFAR10, MNIST ë“±ê³¼ ê°™ì´ ì¼ë°˜ì ìœ¼ë¡œ ì‚¬ìš©í•˜ëŠ” ë°ì´í„°ì…‹ì„ ìœ„í•œ\n",
    "ë°ì´í„° ë¡œë”(data loader), ì¦‰ ``torchvision.datasets`` ê³¼ ì´ë¯¸ì§€ìš© ë°ì´í„° ë³€í™˜ê¸°\n",
    "(data transformer), ì¦‰ ``torch.utils.data.DataLoader`` ê°€ í¬í•¨ë˜ì–´ ìˆìŠµë‹ˆë‹¤.\n",
    "\n",
    "ì´ëŸ¬í•œ ê¸°ëŠ¥ì€ ì—„ì²­ë‚˜ê²Œ í¸ë¦¬í•˜ë©°, ë§¤ë²ˆ ìœ ì‚¬í•œ ì½”ë“œ(boilerplate code)ë¥¼ ë°˜ë³µí•´ì„œ\n",
    "ì‘ì„±í•˜ëŠ” ê²ƒì„ í”¼í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
    "\n",
    "ì˜¤ëŠ˜ì€ CIFAR10 ë°ì´í„°ì…‹ì„ ì‚¬ìš©í•©ë‹ˆë‹¤. ì—¬ê¸°ì—ëŠ” ë‹¤ìŒê³¼ ê°™ì€ ë¶„ë¥˜ë“¤ì´\n",
    "ìˆìŠµë‹ˆë‹¤: 'ë¹„í–‰ê¸°(airplane)', 'ìë™ì°¨(automobile)', 'ìƒˆ(bird)', 'ê³ ì–‘ì´(cat)',\n",
    "'ì‚¬ìŠ´(deer)', 'ê°œ(dog)', 'ê°œêµ¬ë¦¬(frog)', 'ë§(horse)', 'ë°°(ship)', 'íŠ¸ëŸ­(truck)'.\n",
    "ê·¸ë¦¬ê³  CIFAR10ì— í¬í•¨ëœ ì´ë¯¸ì§€ì˜ í¬ê¸°ëŠ” 3x32x32ë¡œ, ì´ëŠ” 32x32 í”½ì…€ í¬ê¸°ì˜ ì´ë¯¸ì§€ê°€\n",
    "3ê°œ ì±„ë„(channel)ì˜ ìƒ‰ìƒìœ¼ë¡œ ì´ë¤„ì ¸ ìˆë‹¤ëŠ” ê²ƒì„ ëœ»í•©ë‹ˆë‹¤.\n",
    "\n",
    ".. figure:: /_static/img/cifar10.png\n",
    "   :alt: cifar10\n",
    "\n",
    "   cifar10\n",
    "\n",
    "\n",
    "## ì´ë¯¸ì§€ ë¶„ë¥˜ê¸° í•™ìŠµí•˜ê¸°\n",
    "\n",
    "ë‹¤ìŒê³¼ ê°™ì€ ë‹¨ê³„ë¡œ ì§„í–‰í•´ë³´ê² ìŠµë‹ˆë‹¤:\n",
    "\n",
    "1. ``torchvision`` ì„ ì‚¬ìš©í•˜ì—¬ CIFAR10ì˜ í•™ìŠµìš© / ì‹œí—˜ìš© ë°ì´í„°ì…‹ì„\n",
    "   ë¶ˆëŸ¬ì˜¤ê³ , ì •ê·œí™”(nomarlizing)í•©ë‹ˆë‹¤.\n",
    "2. í•©ì„±ê³± ì‹ ê²½ë§(Convolution Neural Network)ì„ ì •ì˜í•©ë‹ˆë‹¤.\n",
    "3. ì†ì‹¤ í•¨ìˆ˜ë¥¼ ì •ì˜í•©ë‹ˆë‹¤.\n",
    "4. í•™ìŠµìš© ë°ì´í„°ë¥¼ ì‚¬ìš©í•˜ì—¬ ì‹ ê²½ë§ì„ í•™ìŠµí•©ë‹ˆë‹¤.\n",
    "5. ì‹œí—˜ìš© ë°ì´í„°ë¥¼ ì‚¬ìš©í•˜ì—¬ ì‹ ê²½ë§ì„ ê²€ì‚¬í•©ë‹ˆë‹¤.\n",
    "\n",
    "### 1. CIFAR10ì„ ë¶ˆëŸ¬ì˜¤ê³  ì •ê·œí™”í•˜ê¸°\n",
    "\n",
    "``torchvision`` ì„ ì‚¬ìš©í•˜ì—¬ ë§¤ìš° ì‰½ê²Œ CIFAR10ì„ ë¶ˆëŸ¬ì˜¬ ìˆ˜ ìˆìŠµë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ê°ìì˜ ì»¤ë„ ê°€ìƒí™˜ê²½ì— í•„ìš”í•œ torchì™€ torchvisionì„ ì„¤ì¹˜í•©ë‹ˆë‹¤. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install torch torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "torchvision ë°ì´í„°ì…‹ì˜ ì¶œë ¥(output)ì€ [0, 1] ë²”ìœ„ë¥¼ ê°–ëŠ” PILImage ì´ë¯¸ì§€ì…ë‹ˆë‹¤.\n",
    "ì´ë¥¼ [-1, 1]ì˜ ë²”ìœ„ë¡œ ì •ê·œí™”ëœ Tensorë¡œ ë³€í™˜í•©ë‹ˆë‹¤.\n",
    "\n",
    "<div class=\"alert alert-info\"><h4>Note</h4><p>ë§Œì•½ Windows í™˜ê²½ì—ì„œ BrokenPipeErrorê°€ ë°œìƒí•œë‹¤ë©´,\n",
    "    torch.utils.data.DataLoader()ì˜ num_workerë¥¼ 0ìœ¼ë¡œ ì„¤ì •í•´ë³´ì„¸ìš”.</p></div>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset\n",
    "```python\n",
    "ë°ì´í„° ì…‹ìœ¼ë¡œëŠ” CIFAR10 ë°ì´í„°ì…‹ì„ ì‚¬ìš©í•©ë‹ˆë‹¤.\n",
    "í•„ìš”í•œ ë°ì´í„°ì…‹ì´ë‹ˆ ë‹¤ìš´ë¡œë“œë°›ì•„ì•¼í•©ë‹ˆë‹¤. \n",
    "\n",
    "ğŸ™\n",
    "ì´ë¯¸ì§€ ë¶„ë¥˜ë¥¼ ìœ„í•œ ì¹´í…Œê³ ë¦¬ê°€ ë‹¤ìŒê³¼ ê°™ì´ 10ê°œê°€ ìˆì–´ CIFAR10 ë°ì´í„°ì…‹ì¸ê°€ë³´êµ°ìš”\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "batch_size = 4\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
    "                                        download=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,\n",
    "                                          shuffle=True, num_workers=2)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
    "                                       download=True, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size,\n",
    "                                         shuffle=False, num_workers=2)\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat',\n",
    "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ì¬ë¯¸ì‚¼ì•„ í•™ìŠµìš© ì´ë¯¸ì§€ ëª‡ ê°œë¥¼ ë³´ê² ìŠµë‹ˆë‹¤.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# ì´ë¯¸ì§€ë¥¼ ë³´ì—¬ì£¼ê¸° ìœ„í•œ í•¨ìˆ˜\n",
    "\n",
    "def imshow(img):\n",
    "    img = img / 2 + 0.5     # unnormalize\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# í•™ìŠµìš© ì´ë¯¸ì§€ë¥¼ ë¬´ì‘ìœ„ë¡œ ê°€ì ¸ì˜¤ê¸°\n",
    "dataiter = iter(trainloader)\n",
    "images, labels = next(dataiter)\n",
    "\n",
    "# ì´ë¯¸ì§€ ë³´ì—¬ì£¼ê¸°\n",
    "imshow(torchvision.utils.make_grid(images))\n",
    "# ì •ë‹µ(label) ì¶œë ¥\n",
    "print(' '.join(f'{classes[labels[j]]:5s}' for j in range(batch_size)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ì–´ë–¤ ì´ë¯¸ì§€ê°€ ìˆìœ¼ë©° ì–´ë–¤ ì •ë‹µ ë¼ë²¨ì„ ê°€ì§€ê³  ìˆëŠ”ì§€ í™•ì¸í•´ë³´ì•˜ë‚˜ìš”?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "### 2. í•©ì„±ê³± ì‹ ê²½ë§(Convolution Neural Network) ì •ì˜í•˜ê¸°\n",
    "CNNì— ëŒ€í•´ ìˆ˜ì—…ì‹œê°„ì— í•™ìŠµí–ˆë˜ ë‚´ìš©ë“¤ì„ ë³µìŠµí•˜ë©° ê°ê°ì´ ì–´ë–¤ ì—­í• ì„ í•˜ëŠ” ì½”ë“œì¸ì§€ ë³µìŠµí•´ë´…ì‹œë‹¤.  \n",
    "\n",
    "Conv2d, MaxPool2d, Linear í•¨ìˆ˜ê°€ ì–´ë–¤ ì—­í• ì¼ê¹Œìš”?\n",
    "reluëŠ” í™œì„±í™”í•¨ìˆ˜ì˜ ì¼ì¢…ì¸ê²ƒê°™ì£ ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = torch.flatten(x, 1) # ë°°ì¹˜ë¥¼ ì œì™¸í•œ ëª¨ë“  ì°¨ì›ì„ í‰íƒ„í™”(flatten)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "net = Net()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### nn.Conv2d(3, 6, 5)ëŠ” PyTorchì—ì„œ 2D í•©ì„±ê³± ì¸µ(Convolutional Layer)ì„ ì •ì˜í•˜ëŠ” ë¶€ë¶„ì…ë‹ˆë‹¤. ê° ë§¤ê°œë³€ìˆ˜ì˜ ì˜ë¯¸ëŠ” ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤.\n",
    "\n",
    "ì²« ë²ˆì§¸ ì¸ì (3): ì…ë ¥ ì±„ë„ì˜ ìˆ˜\n",
    "\n",
    "ì´ëŠ” ì…ë ¥ ì´ë¯¸ì§€ì˜ ì±„ë„ ìˆ˜ë¥¼ ì˜ë¯¸í•©ë‹ˆë‹¤.\n",
    "ì—¬ê¸°ì„œëŠ” 3ìœ¼ë¡œ, RGB ì»¬ëŸ¬ ì´ë¯¸ì§€ë¥¼ ì…ë ¥ìœ¼ë¡œ ë°›ëŠ”ë‹¤ëŠ” ê²ƒì„ ë‚˜íƒ€ëƒ…ë‹ˆë‹¤.\n",
    "\n",
    "\n",
    "ë‘ ë²ˆì§¸ ì¸ì (6): ì¶œë ¥ ì±„ë„ì˜ ìˆ˜\n",
    "\n",
    "ì´ëŠ” ì´ í•©ì„±ê³± ì¸µì—ì„œ ìƒì„±í•  íŠ¹ì§• ë§µ(feature map)ì˜ ê°œìˆ˜ì…ë‹ˆë‹¤.\n",
    "ì¦‰, 6ê°œì˜ ì„œë¡œ ë‹¤ë¥¸ í•„í„°(ì»¤ë„)ë¥¼ ì ìš©í•˜ì—¬ 6ê°œì˜ ì¶œë ¥ ì±„ë„ì„ ë§Œë“­ë‹ˆë‹¤.\n",
    "\n",
    "\n",
    "ì„¸ ë²ˆì§¸ ì¸ì (5): ì»¤ë„(í•„í„°)ì˜ í¬ê¸°\n",
    "\n",
    "ì´ëŠ” 5x5 í¬ê¸°ì˜ ì •ì‚¬ê°í˜• í•„í„°ë¥¼ ì‚¬ìš©í•œë‹¤ëŠ” ì˜ë¯¸ì…ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. ì†ì‹¤ í•¨ìˆ˜ì™€ Optimizer ì •ì˜í•˜ê¸°\n",
    "ì†ì‹¤ í•¨ìˆ˜ë¡œëŠ” 1ì£¼ì°¨ ì‹œê°„ì— ì ê¹ ë°°ì› ë˜ multi-class image classificationì—ì„œ ì“°ì˜€ë˜ êµì°¨ ì—”íŠ¸ë¡œí”¼ ì†ì‹¤(Cross-Entropy loss)ë¥¼ ì‚¬ìš©í•˜ë©°\n",
    "OptimizerëŠ” ì•„ì§ í•™ìŠµí•˜ì§€ ì•Šì•˜ì§€ë§Œ ëª¨ë©˜í…€(momentum) ê°’ì„ ê°–ëŠ” SGDë¥¼ ì‚¬ìš©í•´ë´…ì‹œë‹¤.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. ì‹ ê²½ë§ í•™ìŠµí•˜ê¸°\n",
    "\n",
    "ì´ì œ ì¬ë¯¸ìˆëŠ” ë¶€ë¶„ì´ ì‹œì‘ë©ë‹ˆë‹¤.\n",
    "ë‹¨ìˆœíˆ ë°ì´í„°ë¥¼ ë°˜ë³µí•´ì„œ ì‹ ê²½ë§ì— ì…ë ¥ìœ¼ë¡œ ì œê³µí•˜ê³ , ìµœì í™”(Optimize)ë§Œ í•˜ë©´\n",
    "ë©ë‹ˆë‹¤.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(2):   # ë°ì´í„°ì…‹ì„ ìˆ˜ì°¨ë¡€ ë°˜ë³µí•©ë‹ˆë‹¤.\n",
    "\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        # [inputs, labels]ì˜ ëª©ë¡ì¸ dataë¡œë¶€í„° ì…ë ¥ì„ ë°›ì€ í›„;\n",
    "        inputs, labels = data\n",
    "\n",
    "        # ë³€í™”ë„(Gradient) ë§¤ê°œë³€ìˆ˜ë¥¼ 0ìœ¼ë¡œ ë§Œë“¤ê³ \n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # ìˆœì „íŒŒ + ì—­ì „íŒŒ + ìµœì í™”ë¥¼ í•œ í›„\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # í†µê³„ë¥¼ ì¶œë ¥í•©ë‹ˆë‹¤.\n",
    "        running_loss += loss.item()\n",
    "        if i % 2000 == 1999:    # print every 2000 mini-batches\n",
    "            print(f'[{epoch + 1}, {i + 1:5d}] loss: {running_loss / 2000:.3f}')\n",
    "            running_loss = 0.0\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "í•™ìŠµí•œ ëª¨ë¸ì„ ì €ì¥í•´ë³´ê² ìŠµë‹ˆë‹¤:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = './cifar_net.pth'\n",
    "torch.save(net.state_dict(), PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### 5. ì‹œí—˜ìš© ë°ì´í„°ë¡œ ì‹ ê²½ë§ ê²€ì‚¬í•˜ê¸°\n",
    "\n",
    "ì§€ê¸ˆê¹Œì§€ í•™ìŠµìš© ë°ì´í„°ì…‹ì„ 2íšŒ ë°˜ë³µí•˜ë©° ì‹ ê²½ë§ì„ í•™ìŠµì‹œì¼°ìŠµë‹ˆë‹¤.\n",
    "ì‹ ê²½ë§ì´ ì „í˜€ ë°°ìš´ê²Œ ì—†ì„ì§€ë„ ëª¨ë¥´ë‹ˆ í™•ì¸í•´ë´…ë‹ˆë‹¤.\n",
    "\n",
    "ì‹ ê²½ë§ì´ ì˜ˆì¸¡í•œ ì¶œë ¥ê³¼ ì§„ì§œ ì •ë‹µ(Ground-truth)ì„ ë¹„êµí•˜ëŠ” ë°©ì‹ìœ¼ë¡œ í™•ì¸í•©ë‹ˆë‹¤.\n",
    "ë§Œì•½ ì˜ˆì¸¡ì´ ë§ë‹¤ë©´ ìƒ˜í”Œì„ 'ë§ì€ ì˜ˆì¸¡ê°’(correct predictions)' ëª©ë¡ì— ë„£ê² ìŠµë‹ˆë‹¤.\n",
    "\n",
    "ì²«ë²ˆì§¸ë¡œ ì‹œí—˜ìš© ë°ì´í„°ë¥¼ ì¢€ ë³´ê² ìŠµë‹ˆë‹¤.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataiter = iter(testloader)\n",
    "images, labels = next(dataiter)\n",
    "\n",
    "# ì´ë¯¸ì§€ë¥¼ ì¶œë ¥í•©ë‹ˆë‹¤.\n",
    "imshow(torchvision.utils.make_grid(images))\n",
    "print('GroundTruth: ', ' '.join(f'{classes[labels[j]]:5s}' for j in range(4)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ì´ì œ, ì €ì¥í–ˆë˜ ëª¨ë¸ì„ ë¶ˆëŸ¬ì˜¤ë„ë¡ í•˜ê² ìŠµë‹ˆë‹¤ (ì£¼: ëª¨ë¸ì„ ì €ì¥í•˜ê³  ë‹¤ì‹œ ë¶ˆëŸ¬ì˜¤ëŠ”\n",
    "ì‘ì—…ì€ ì—¬ê¸°ì—ì„œëŠ” ë¶ˆí•„ìš”í•˜ì§€ë§Œ, ì–´ë–»ê²Œ í•˜ëŠ”ì§€ ì„¤ëª…ì„ ìœ„í•´ í•´ë³´ê² ìŠµë‹ˆë‹¤):\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = Net()\n",
    "net.load_state_dict(torch.load(PATH))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ì¢‹ìŠµë‹ˆë‹¤, ì´ì œ ì´ ì˜ˆì œë“¤ì„ ì‹ ê²½ë§ì´ ì–´ë–»ê²Œ ì˜ˆì¸¡í–ˆëŠ”ì§€ë¥¼ ë³´ê² ìŠµë‹ˆë‹¤:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = net(images)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ì¶œë ¥ì€ 10ê°œ ë¶„ë¥˜ ê°ê°ì— ëŒ€í•œ ê°’ìœ¼ë¡œ ë‚˜íƒ€ë‚©ë‹ˆë‹¤. ì–´ë–¤ ë¶„ë¥˜ì— ëŒ€í•´ì„œ ë” ë†’ì€ ê°’ì´\n",
    "ë‚˜íƒ€ë‚œë‹¤ëŠ” ê²ƒì€, ì‹ ê²½ë§ì´ ê·¸ ì´ë¯¸ì§€ê°€ í•´ë‹¹ ë¶„ë¥˜ì— ë” ê°€ê¹ë‹¤ê³  ìƒê°í•œë‹¤ëŠ” ê²ƒì…ë‹ˆë‹¤.\n",
    "ë”°ë¼ì„œ, ê°€ì¥ ë†’ì€ ê°’ì„ ê°–ëŠ” ì¸ë±ìŠ¤(index)ë¥¼ ë½‘ì•„ë³´ê² ìŠµë‹ˆë‹¤:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, predicted = torch.max(outputs, 1)\n",
    "\n",
    "print('Predicted: ', ' '.join(f'{classes[predicted[j]]:5s}'\n",
    "                              for j in range(4)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ê²°ê³¼ê°€ ê´œì°®ì•„ë³´ì´ë„¤ìš”.\n",
    "\n",
    "ê·¸ëŸ¼ ì „ì²´ ë°ì´í„°ì…‹ì— ëŒ€í•´ì„œëŠ” ì–´ë–»ê²Œ ë™ì‘í•˜ëŠ”ì§€ ë³´ê² ìŠµë‹ˆë‹¤.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "# í•™ìŠµ ì¤‘ì´ ì•„ë‹ˆë¯€ë¡œ, ì¶œë ¥ì— ëŒ€í•œ ë³€í™”ë„ë¥¼ ê³„ì‚°í•  í•„ìš”ê°€ ì—†ìŠµë‹ˆë‹¤\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "        # ì‹ ê²½ë§ì— ì´ë¯¸ì§€ë¥¼ í†µê³¼ì‹œì¼œ ì¶œë ¥ì„ ê³„ì‚°í•©ë‹ˆë‹¤\n",
    "        outputs = net(images)\n",
    "        # ê°€ì¥ ë†’ì€ ê°’(energy)ë¥¼ ê°–ëŠ” ë¶„ë¥˜(class)ë¥¼ ì •ë‹µìœ¼ë¡œ ì„ íƒí•˜ê² ìŠµë‹ˆë‹¤\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print(f'Accuracy of the network on the 10000 test images: {100 * correct // total} %')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(10ê°€ì§€ ë¶„ë¥˜ ì¤‘ì— í•˜ë‚˜ë¥¼ ë¬´ì‘ìœ„ë¡œ) ì°ì—ˆì„ ë•Œì˜ ì •í™•ë„ì¸ 10% ë³´ë‹¤ëŠ” ë‚˜ì•„ë³´ì…ë‹ˆë‹¤.\n",
    "ì‹ ê²½ë§ì´ ë­”ê°€ ë°°ìš°ê¸´ í•œ ê²ƒ ê°™ë„¤ìš”.\n",
    "\n",
    "ê·¸ëŸ¼ ì–´ë–¤ ê²ƒë“¤ì„ ë” ì˜ ë¶„ë¥˜í•˜ê³ , ì–´ë–¤ ê²ƒë“¤ì„ ë” ëª»í–ˆëŠ”ì§€ ì•Œì•„ë³´ê² ìŠµë‹ˆë‹¤:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ê° ë¶„ë¥˜(class)ì— ëŒ€í•œ ì˜ˆì¸¡ê°’ ê³„ì‚°ì„ ìœ„í•´ ì¤€ë¹„\n",
    "correct_pred = {classname: 0 for classname in classes}\n",
    "total_pred = {classname: 0 for classname in classes}\n",
    "\n",
    "# ë³€í™”ë„ëŠ” ì—¬ì „íˆ í•„ìš”í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "        outputs = net(images)\n",
    "        _, predictions = torch.max(outputs, 1)\n",
    "        # ê° ë¶„ë¥˜ë³„ë¡œ ì˜¬ë°”ë¥¸ ì˜ˆì¸¡ ìˆ˜ë¥¼ ëª¨ìë‹ˆë‹¤\n",
    "        for label, prediction in zip(labels, predictions):\n",
    "            if label == prediction:\n",
    "                correct_pred[classes[label]] += 1\n",
    "            total_pred[classes[label]] += 1\n",
    "\n",
    "\n",
    "# ê° ë¶„ë¥˜ë³„ ì •í™•ë„(accuracy)ë¥¼ ì¶œë ¥í•©ë‹ˆë‹¤\n",
    "for classname, correct_count in correct_pred.items():\n",
    "    accuracy = 100 * float(correct_count) / total_pred[classname]\n",
    "    print(f'Accuracy for class: {classname:5s} is {accuracy:.1f} %')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ğŸ‰ğŸ‰ğŸ‰ 2ì£¼ì°¨ ê³¼ì œ ì™„ë£Œ! ğŸ‰ğŸ‰ğŸ‰\n",
    "```python\n",
    "ğŸ™\n",
    "ì—¬ëŸ¬ë¶„ ëª¨ë‘ ìˆ˜ê³  í–ˆì–´ìš”!! ì¶”ì„ ê³¼ì œë¥¼ completeí•œ ë‹¹ì‹ ì—ê²Œ í–‰ìš´ì„ ë“œë¦½ë‹ˆë‹¤. ë‹¤ìŒ ë¯¸ì…˜ì€ ì„ íƒ ì œì¶œì…ë‹ˆë‹¤.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "``` python \n",
    "ğŸ“ ë¯¸ì…˜:\n",
    "\n",
    "1. ê°•ì˜ë¡ p42ì™€ ìœ ì‚¬í•œ CNN êµ¬ì¡° ë„ì‹ì„ ì†ìœ¼ë¡œ ê·¸ë¦¬ê¸° (ë°œê·¸ë¦¼ì´ì–´ë„ ê´œì°®)\n",
    "2. ìœ„ì—ì„œ ì •ì˜í•œ class Net(nn.Module)ì˜ ì´ í•™ìŠµ ê°€ëŠ¥í•œ íŒŒë¼ë¯¸í„° ê°œìˆ˜ êµ¬í•˜ê¸° (ì •ë‹µì´ ë§ì•„ì•¼í•¨. 1íšŒ ë„ì „ë§Œ ê°€ëŠ¥)\n",
    "\n",
    "\n",
    "ğŸ† ë³´ìƒ:\n",
    "\n",
    "ì •ë‹µì„ ë§íˆê³  ì†ê·¸ë¦¼ ë„ì‹ê³¼ ê³„ì‚° ê³¼ì •ì„ ë””ìŠ¤ì½”ë“œ DMìœ¼ë¡œ ì¸ì¦í•œ ë‹¹ì‹ ì—ê²Œ ì»¤í”¼ ì¿ í°ì„ ë“œë¦½ë‹ˆë‹¤! (ë©˜í†  ì‚¬ë¹„ë¡œ ì¦ì •, ë‹¨ ì„ ì°©ìˆœ 5ì¸ì—ê²Œë§Œ í•´ë‹¹)\n",
    "\n",
    "ğŸ•’ ê¸°í•œ: [24.10.01]\n",
    "ğŸ“¬ ì œì¶œ: DMìœ¼ë¡œ ì¸ì¦ìƒ· ì „ì†¡\n",
    "\n",
    "ì, ì—¬ëŸ¬ë¶„ì˜ ë‡Œë¥¼ ê¹¨ì›Œ CNNì„ ì •ë³µí•˜ê³  ì»¤í”¼ë¥¼ ë°›ì•„ê°€ì„¸ìš”. í–‰ìš´ì„ ë¹•ë‹ˆë‹¤! ğŸ€\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
